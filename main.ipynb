{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import train\n",
    "from bin_packing_dataset import BinPackingDataset\n",
    "from bin_packing_model import BinPackingLSTMModel\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos la semilla para que los resultados sean reproducibles\n",
    "SEED = 23\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Num Workers: 0\n"
     ]
    }
   ],
   "source": [
    "# Algunas constantes\n",
    "\n",
    "# definimos el dispositivo que vamos a usar\n",
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "\n",
    "NUM_WORKERS = 0 # max(os.cpu_count() - 1, 1)  # número de workers para cargar los datos\n",
    "\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Num Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 81000\n",
      "Container: tensor([14., 11.])\n",
      "Boxes: tensor([[ 8.,  7.],\n",
      "        [12.,  2.],\n",
      "        [ 1.,  2.],\n",
      "        [ 2.,  7.],\n",
      "        [ 4.,  8.],\n",
      "        [ 0.,  0.]])\n",
      "Train dataset size: 56700\n",
      "Val dataset size: 16200\n",
      "Test dataset size: 8100\n"
     ]
    }
   ],
   "source": [
    "#Creacion del dataset de entrenamiento, validacion y test\n",
    "\n",
    "full_dataset = BinPackingDataset('data')\n",
    "print('Full dataset size:', len(full_dataset))\n",
    "container_tensor, boxes_tensor = full_dataset[0]\n",
    "print('Container:', container_tensor)\n",
    "print('Boxes:', boxes_tensor)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [int(0.7*len(full_dataset)), int(0.20*len(full_dataset)), int(0.10*len(full_dataset))])\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "print('Test dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del primer contenedor: torch.Size([500, 2])\n",
      "Tamaño de las cajas del primer contenedor: torch.Size([500, 11, 2])\n"
     ]
    }
   ],
   "source": [
    "# Collate para manejar secuencias de diferentes longitudes\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "def custom_collate_fn_with_padding(batch):\n",
    "    \"\"\"\n",
    "    Collate function que mantiene la estructura de contenedor y agrega padding a las secuencias de cajas.\n",
    "    \n",
    "    Args:\n",
    "        batch (list): Lista de tuplas (contenedor, cajas).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (contenedores, cajas_padded, longitudes) donde:\n",
    "            - contenedores: Tensor de tamaño (batch_size, 2).\n",
    "            - cajas_padded: Tensor de tamaño (batch_size, max_len, 2) con padding.\n",
    "            - longitudes: Tensor de tamaños originales de las secuencias de cajas.\n",
    "    \"\"\"\n",
    "    containers = torch.stack([item[0] for item in batch])  # Contenedores como tensor\n",
    "    boxes = [item[1] for item in batch]  # Lista de cajas\n",
    "    \n",
    "    # Padding de las secuencias de cajas (rellenar con ceros hasta la longitud máxima en el batch)\n",
    "    boxes_padded = rnn_utils.pad_sequence(boxes, batch_first=True)\n",
    "    \n",
    "    # Longitudes originales de cada secuencia de cajas\n",
    "    lengths = torch.tensor([len(b) for b in boxes])\n",
    "    \n",
    "    return containers, boxes_padded\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "mock_loader = torch.utils.data.DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn_with_padding)\n",
    "\n",
    "x, y = next(iter(mock_loader))\n",
    "print('Tamaño del primer contenedor:', x.shape)\n",
    "print('Tamaño de las cajas del primer contenedor:', y.shape)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn_with_padding)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn_with_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AutoRegressiveBinPackingModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, max_dim, n_layers, dropout=0.1):\n",
    "        super(AutoRegressiveBinPackingModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.max_dim = max_dim\n",
    "        \n",
    "        # Embedding para entrada (contenedor y cajas)\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # LSTM para modelar secuencias\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Proyección para obtener logits de distribuciones de width y height\n",
    "        self.fc_width = nn.Linear(hidden_dim, max_dim + 1)  # +1 para incluir el token EOS\n",
    "        self.fc_height = nn.Linear(hidden_dim, max_dim + 1)\n",
    "    \n",
    "    def forward(self, container, target_seq=None, seq_len=100, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            container: Tensor con las dimensiones del contenedor (batch_size, input_dim).\n",
    "            target_seq: Secuencia objetivo durante entrenamiento (batch_size, seq_len, input_dim).\n",
    "            seq_len: Longitud máxima de secuencia durante generación.\n",
    "            teacher_forcing_ratio: Probabilidad de usar teacher forcing (0.0 a 1.0).\n",
    "        \n",
    "        Returns:\n",
    "            Logits para distribuciones de width y height.\n",
    "        \"\"\"\n",
    "        container_emb = self.embedding(container).unsqueeze(1)  # (batch_size, 1, hidden_dim)\n",
    "        \n",
    "        # Para almacenar las salidas durante la generación\n",
    "        outputs_width = []\n",
    "        outputs_height = []\n",
    "        \n",
    "        # Estado inicial\n",
    "        generated_seq = container_emb\n",
    "        hidden = None\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            output, hidden = self.lstm(generated_seq, hidden)  # (batch_size, 1, hidden_dim)\n",
    "            \n",
    "            # Logits para width y height\n",
    "            logits_width = self.fc_width(output[:, -1, :])  # (batch_size, max_dim+1)\n",
    "            logits_height = self.fc_height(output[:, -1, :])  # (batch_size, max_dim+1)\n",
    "            outputs_width.append(logits_width)\n",
    "            outputs_height.append(logits_height)\n",
    "            \n",
    "            if target_seq is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                # Usar la secuencia objetivo (teacher forcing)\n",
    "                next_box = target_seq[:, t, :]  # (batch_size, 2)\n",
    "            else:\n",
    "                # Sampleo de la predicción\n",
    "                prob_width = F.softmax(logits_width, dim=-1)  # (batch_size, max_dim+1)\n",
    "                prob_height = F.softmax(logits_height, dim=-1)  # (batch_size, max_dim+1)\n",
    "                next_width = torch.multinomial(prob_width, num_samples=1)  # (batch_size, 1)\n",
    "                next_height = torch.multinomial(prob_height, num_samples=1)  # (batch_size, 1)\n",
    "                next_box = torch.cat([next_width, next_height], dim=1)  # (batch_size, 2)\n",
    "            \n",
    "            # Preparar la entrada para el siguiente paso\n",
    "            next_box_emb = self.embedding(next_box.float())  # Convertir a embedding\n",
    "            # Concatenamos la secuencia generada con la nueva caja\n",
    "            generated_seq = torch.cat([generated_seq, next_box_emb.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        # Apilar las salidas\n",
    "        logits_width = torch.stack(outputs_width, dim=1)  # (batch_size, seq_len, max_dim+1)\n",
    "        logits_height = torch.stack(outputs_height, dim=1)  # (batch_size, seq_len, max_dim+1)\n",
    "        return logits_width, logits_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.7722923504678825\n",
      "Epoch 2/50, Loss: 4.6794328313124804\n",
      "Epoch 3/50, Loss: 3.9276059991435\n",
      "Epoch 4/50, Loss: 3.4729884591018942\n",
      "Epoch 5/50, Loss: 3.2202146722559344\n",
      "Epoch 6/50, Loss: 3.0963145766341897\n",
      "Epoch 7/50, Loss: 3.007576448875561\n",
      "Epoch 8/50, Loss: 2.956689608724494\n",
      "Epoch 9/50, Loss: 2.9169732917819107\n",
      "Epoch 10/50, Loss: 2.876465441887839\n",
      "Epoch 11/50, Loss: 2.851640218182614\n",
      "Epoch 12/50, Loss: 2.8290247415241443\n",
      "Epoch 13/50, Loss: 2.817302517723619\n",
      "Epoch 14/50, Loss: 2.812607915777909\n",
      "Epoch 15/50, Loss: 2.7937937305684675\n",
      "Epoch 16/50, Loss: 2.7811428643109504\n",
      "Epoch 17/50, Loss: 2.7702592841365883\n",
      "Epoch 18/50, Loss: 2.768784288774457\n",
      "Epoch 19/50, Loss: 2.7553714513778687\n",
      "Epoch 20/50, Loss: 2.7502574042270056\n",
      "Epoch 21/50, Loss: 2.753992929793241\n",
      "Epoch 22/50, Loss: 2.7502171533149586\n",
      "Epoch 23/50, Loss: 2.7365178413558424\n",
      "Epoch 24/50, Loss: 2.737500728222362\n",
      "Epoch 25/50, Loss: 2.734319074112072\n",
      "Epoch 26/50, Loss: 2.735385166971307\n",
      "Epoch 27/50, Loss: 2.731098871482046\n",
      "Epoch 28/50, Loss: 2.723052323910228\n",
      "Epoch 29/50, Loss: 2.7169766823450723\n",
      "Epoch 30/50, Loss: 2.7307350719184207\n",
      "Epoch 31/50, Loss: 2.7166955722005746\n",
      "Epoch 32/50, Loss: 2.7201153165415715\n",
      "Epoch 33/50, Loss: 2.711181584157442\n",
      "Epoch 34/50, Loss: 2.7142698283781086\n",
      "Epoch 35/50, Loss: 2.7060869513896475\n",
      "Epoch 36/50, Loss: 2.7252127496819747\n",
      "Epoch 37/50, Loss: 2.715175423705787\n",
      "Epoch 38/50, Loss: 2.7044118015389693\n",
      "Epoch 39/50, Loss: 2.7120506533405235\n",
      "Epoch 40/50, Loss: 2.7024737387372735\n",
      "Epoch 41/50, Loss: 2.7030828354651466\n",
      "Epoch 42/50, Loss: 2.704662559325235\n",
      "Epoch 43/50, Loss: 2.7010682382081685\n",
      "Epoch 44/50, Loss: 2.7015686369778815\n",
      "Epoch 45/50, Loss: 2.696553376683018\n",
      "Epoch 46/50, Loss: 2.6968074054048774\n",
      "Epoch 47/50, Loss: 2.7018437197333887\n",
      "Epoch 48/50, Loss: 2.696285689086245\n",
      "Epoch 49/50, Loss: 2.6868752199306822\n",
      "Epoch 50/50, Loss: 2.698820193608602\n"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "MAX_DIM = 20\n",
    "input_dim = 2\n",
    "hidden_dim = 30\n",
    "n_layers = 2\n",
    "dropout = 0\n",
    "epochs = 50\n",
    "teacher_forcing_ratio = 1.0  # Iniciamos con teacher forcing completo\n",
    "teacher_forcing_decay = 0.95  # Decae 5% por época\n",
    "\n",
    "# Modelo\n",
    "model = AutoRegressiveBinPackingModel(input_dim, hidden_dim, MAX_DIM, n_layers, dropout)\n",
    "model.to(DEVICE)\n",
    "# Hiperparámetros\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "teacher_forcing_ratio = 0.5  # 50% de probabilidad de usar teacher forcing\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    teacher_forcing_ratio *= teacher_forcing_decay  # Reducimos el ratio por cada época\n",
    "    train_loss = 0\n",
    "    \n",
    "    for container, target_seq in train_dataloader:\n",
    "        container = container.to(DEVICE)\n",
    "        target_seq = target_seq.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits_width, logits_height = model(\n",
    "            container, \n",
    "            target_seq=target_seq, \n",
    "            seq_len=target_seq.size(1), \n",
    "            teacher_forcing_ratio=teacher_forcing_ratio\n",
    "        )\n",
    "        \n",
    "        # Aplanar las salidas para calcular la pérdida\n",
    "        target_width = target_seq[:, :, 0].long()  # (batch_size, seq_len)\n",
    "        target_height = target_seq[:, :, 1].long()  # (batch_size, seq_len)\n",
    "        loss_width = criterion(logits_width.view(-1, MAX_DIM+1), target_width.view(-1))\n",
    "        loss_height = criterion(logits_height.view(-1, MAX_DIM+1), target_height.view(-1))\n",
    "        \n",
    "        loss = loss_width + loss_height\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_dataloader)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BinPackingGame, Box, ResolvedBinPackingGameResult\n",
    "dataset_keys = set()\n",
    "\n",
    "def tensor_to_box(tensor):\n",
    "    return Box(int(tensor[0].item()), int(tensor[1].item()))\n",
    "    \n",
    "\n",
    "for container_tensor, boxes_tensor in test_dataset:\n",
    "\n",
    "    boxes = [tensor_to_box(tensor) for tensor in boxes_tensor]\n",
    "\n",
    "    game = BinPackingGame(tensor_to_box(container_tensor), boxes)\n",
    "    game_key = game.generate_unique_key()\n",
    "    dataset_keys.add(game_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container.shape=torch.Size([1, 2])\n",
      "Secuencia generada:\n",
      "Ancho: 3, Alto: 3\n",
      "Ancho: 9, Alto: 8\n",
      "Ancho: 11, Alto: 2\n",
      "Ancho: 7, Alto: 2\n",
      "Ancho: 8, Alto: 5\n",
      "Ancho: 0, Alto: 1\n",
      "Ancho: 0, Alto: 0\n",
      "Ancho: 7, Alto: 0\n",
      "Ancho: 0, Alto: 0\n",
      "Ancho: 0, Alto: 0\n"
     ]
    }
   ],
   "source": [
    "def generate_sequence(model, container, max_seq_len=10, teacher_forcing_ratio=0.0):\n",
    "    \"\"\"\n",
    "    Genera una secuencia de cajas para un contenedor dado utilizando un modelo entrenado.\n",
    "    \n",
    "    Args:\n",
    "        model: El modelo entrenado.\n",
    "        container: Tensor con las dimensiones del contenedor (batch_size, input_dim).\n",
    "        max_seq_len: Longitud máxima de la secuencia que se desea generar.\n",
    "        teacher_forcing_ratio: Probabilidad de usar teacher forcing (aunque normalmente se usa 0.0 aquí).\n",
    "        \n",
    "    Returns:\n",
    "        Secuencia generada de dimensiones (seq_len, 2), con el formato de (width, height).\n",
    "    \"\"\"\n",
    "    model.eval()  # Poner el modelo en modo evaluación\n",
    "    \n",
    "    # Verifica que el contenedor sea bidimensional\n",
    "    if container.ndim == 1:\n",
    "        container = container.unsqueeze(0)  # Convertir a (1, input_dim)\n",
    "    container = container.to(DEVICE)  # (batch_size, input_dim)\n",
    "    \n",
    "    # Embedding inicial del contenedor\n",
    "    container_emb = model.embedding(container).unsqueeze(1)  # (batch_size, 1, hidden_dim)\n",
    "\n",
    "    # Inicializa la secuencia generada y el estado oculto del LSTM\n",
    "    generated_seq = container_emb\n",
    "    hidden = None\n",
    "    generated_boxes = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_seq_len):\n",
    "            # Paso del LSTM\n",
    "            output, hidden = model.lstm(generated_seq, hidden)  # (batch_size, seq_len, hidden_dim)\n",
    "            \n",
    "            # Logits para predicciones de width y height\n",
    "            logits_width = model.fc_width(output[:, -1, :])  # (batch_size, max_dim+1)\n",
    "            logits_height = model.fc_height(output[:, -1, :])  # (batch_size, max_dim+1)\n",
    "            \n",
    "            # Predicciones\n",
    "            prob_width = F.softmax(logits_width, dim=-1)\n",
    "            prob_height = F.softmax(logits_height, dim=-1)\n",
    "            next_width = torch.multinomial(prob_width, num_samples=1).squeeze(-1)  # (batch_size,)\n",
    "            next_height = torch.multinomial(prob_height, num_samples=1).squeeze(-1)  # (batch_size,)\n",
    "\n",
    "            # Construir la siguiente caja\n",
    "            next_box = torch.stack([next_width, next_height], dim=1)  # (batch_size, 2)\n",
    "            generated_boxes.append(next_box.cpu().numpy())  # Guardar la predicción\n",
    "            \n",
    "            # Embedding de la siguiente caja\n",
    "            next_box_emb = model.embedding(next_box.float().to(DEVICE)).unsqueeze(1)  # (batch_size, 1, hidden_dim)\n",
    "\n",
    "            # Actualiza la secuencia generada agregando la nueva caja\n",
    "            generated_seq = torch.cat([generated_seq, next_box_emb], dim=1)\n",
    "\n",
    "    return generated_boxes\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "container = torch.tensor([[10, 10]], dtype=torch.float32)  # Ejemplo de contenedor (width=10, height=10)\n",
    "print(f\"{container.shape=}\")\n",
    "generated_seq = generate_sequence(model, container, max_seq_len=10, teacher_forcing_ratio=0.0)\n",
    "\n",
    "# Mostrar la secuencia generada\n",
    "print(\"Secuencia generada:\")\n",
    "for box in generated_seq:\n",
    "    print(f\"Ancho: {box[0][0]}, Alto: {box[0][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid games: 70/100\n",
      "Unique games: 42/100\n",
      "unique_games keys: {'c46fd767b93f191d34251bfcc9c31e16', '7360981b7d7de4a07a64af58c3726227', 'bf184ed5419ff413cde64f2fa28f3e7d', '40dfa7ba1f4b2b3d9373780a76f4d033', '6f2984b9e9017d373b4bcd89e50674a4', 'b68746c88a269991906cdc69e82e360e', '2ea69f3fa1270e76ff0b70bd56d946a1', '1943513420048c4b1ebf8b41f330c366', 'a57db73d2d4532b27d6f8dfd87a4e62f', 'd96f163ce5de04e2b98f1a3ef123b3f8', '88d0d9418e7d79024cb201a033a53293', '3bf244e0874c6e2e1215ebb22f59c3b9', '500d8ffc0fd7eb4e1e472448aa92e17c', '3420c1115e18f942883a0bad984ddd9b', 'd3246c7f3bef43bb5fba936b37828f4b', 'd19aedb66799e8563c24046d52980ccb', '779aedcec57697ea3f0829bda5c4b89a', '6d13666e3b6f45cb7f1fcee9100959f9', '4a218ff8e2bcfc984bdaed7fbfbcd04f', 'dc553004cfdfe266f1cb3a029cc59c23', '02c32d31ba63860306b4f4e0ef4c4e18', 'c4ee3ff94e73fe6c6de1991ac596cdc7', '9f8f7c19dc52df6a5e9a0af94f274772', '111a547ef122c65aff6b216eb6b09626', 'ba0d8294824c0987370b3bc20385f036', 'c333852032773fc6f0e13ff6f877524a', 'd9f900dc85bbe822f8740e8d66007e1d', 'e2696db89cbe82d266b537e9a7654560', '671fb3ad6795e10aa43bdcd4aaa6ae10', '1ed9da685193bafd3c48ed3342d014eb', '98d799c0fc3377880f8c51a6e66bd096', '02c8493d3a46402a34e9ef61e79e6b36', '3e28eb80c86c3282426b936498278b6f', 'fd673b090314565b52e95fed122e6e70', '7c66e7ab20d16ebb8818c3da65365d87', 'e97d210fb465dede29daab2f6f278236', 'cee9f175828bff897674adcdd83a6b68', '02d736a24e1b54853fc4ef340cb59910', '9ce984eb6dd044c0c0059395935c50da', '62e0d55fcb24573582848af6bf6adc76', '2e42c7def7739ccb5d849dce736bc349', 'd983dd24c0077d334792dbce5c9b5894'}\n",
      "Coverages: {0.078125, 0.015625, 0.046875, 0.25, 0.546875, 0.09375, 0.375, 0.125, 0.21875, 0.1875, 0.28125, 0.03125, 0.0625, 0.109375, 0.65625, 0.234375, 0.5625, 0.328125, 0.3125, 0.4375, 0.0, 0.15625, 0.390625, 0.765625}\n",
      "New games: 42\n",
      "Boxes count: Counter({1: 68, 0: 2})\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=11)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=12, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=9)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=10)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=10)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=8, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=10, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=8, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=11)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=10, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=14, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=13, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=7)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=9, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=9, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=5, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=5, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=7)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=11, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=9)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=10, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=9, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=13)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=12)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=15)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=13, height=8)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=9)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=11)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=5, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=18)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=10, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=6)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=9, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=8, height=11)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=11, height=5)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=1, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=5, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=7, height=7)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=4)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=5, height=2)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=3, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=6, height=3)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=12, height=10)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=1)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=4, height=10)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=7)])\n",
      "BinPackingGame(container=Box(width=8, height=8), boxes=[Box(width=2, height=10)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Counter\n",
    "\n",
    "from models import BinPackingGame, Box\n",
    "\n",
    "\n",
    "# Generación de cajas\n",
    "container_width = 8\n",
    "container_height = 8\n",
    "\n",
    "attempts = 100\n",
    "valid_games = 0\n",
    "games = []\n",
    "unique_games = set()\n",
    "coverages = set()\n",
    "boxes_count = Counter()\n",
    "new_games = 0\n",
    "model.eval()\n",
    "for i in range(attempts):\n",
    "    container = torch.tensor([[container_width, container_height]],dtype=torch.float32).to(DEVICE)\n",
    "    generated_boxes = generate_sequence(model, container, max_seq_len=10, teacher_forcing_ratio=0.0)\n",
    "\n",
    "    # Paso 2: Convertir a lista de tuplas\n",
    "    # box_list = [tensor_to_box(tensor) for tensor in output]\n",
    "\n",
    "    boxes = [Box(int(box_width), int(box_height)) for(box_width, box_height) in generated_boxes]\n",
    "\n",
    "    valid_boxes = [box for box in boxes if box.width > 0 and box.height > 0]\n",
    "\n",
    "    game = BinPackingGame(Box(container_width, container_height), valid_boxes)\n",
    "    games.append(game)\n",
    "    result = game.solve()\n",
    "    if isinstance(result, ResolvedBinPackingGameResult):\n",
    "        valid_games += 1\n",
    "        game_key = game.generate_unique_key()\n",
    "        boxes_count[len(game.boxes)] += 1\n",
    "        # print(f'{game_key=}')\n",
    "        if game_key not in unique_games:\n",
    "            unique_games.add(game_key)\n",
    "            coverages.add(game.coverage())\n",
    "            if game_key not in dataset_keys:\n",
    "                new_games += 1\n",
    "\n",
    "print(f\"Valid games: {valid_games}/{attempts}\")\n",
    "print(f\"Unique games: {len(unique_games)}/{attempts}\")\n",
    "print(f\"unique_games keys: {unique_games}\")\n",
    "print(f\"Coverages: {coverages}\")\n",
    "print(f\"New games: {new_games}\")\n",
    "print(f\"Boxes count: {boxes_count}\")\n",
    "[print(f'{game}') for game in games]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
